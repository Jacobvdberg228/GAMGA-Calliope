{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "\n",
    "import calliope\n",
    "from calliope.exceptions import ModelWarning\n",
    "\n",
    "calliope.set_log_verbosity(verbosity='critical', include_solver_output=False, capture_warnings=False)\n",
    "\n",
    "# Suppress the specific ModelWarning from Calliope\n",
    "warnings.filterwarnings(\"ignore\", category=ModelWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input variables\n",
    "NUM_SUBPOPS = 2 # number of populations\n",
    "SUBPOP_SIZE = 4 #size of populations. Must be even due to crossover\n",
    "GENERATIONS = 100 #amount of generations\n",
    "\n",
    "INDCROSS = 0.5 #chance for value of individual to be crossed over\n",
    "INDMUT = 0.2 #chance for individual to mutate\n",
    "ETAV = 1 #small value (1 or smaller) creates different values from parents, high value (20 or higher) creates resembling values\n",
    "\n",
    "\n",
    "# changing values/resolution after n amount of generations\n",
    "value_change_1 = 21  \n",
    "value_change_2 = 60 \n",
    "\n",
    "# change to other resolution after n amount of generations\n",
    "resolution_change_1 = 90\n",
    "\n",
    "# slack value\n",
    "max_slack = 0.2\n",
    "\n",
    "# Replace with a reasonable maximum if applicable this is already 1 = 1000GW\n",
    "max_cap_value = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model with a resolution of 14 days\n",
    "model_14D = calliope.Model('C:/Users/Jacob/Desktop/PythonProjects/GAMGA-Calliope v3.9/GAMGA_model/model_1M.yaml')\n",
    "model_14D.run()\n",
    "\n",
    "df_total_cost_14D = model_14D.results.cost.to_series().dropna()\n",
    "total_cost_optimal_14D = df_total_cost_14D.loc[~df_total_cost_14D.index.map(str).str.contains('co2_emissions')].sum()\n",
    "\n",
    "energy_cap_df_14D = model_14D.results.energy_cap.to_pandas()\n",
    "filtered_energy_cap_df_14D = energy_cap_df_14D[~energy_cap_df_14D.index.str.contains(\"demand|transmission\")]\n",
    "\n",
    "# #create the model with a resolution of 14 days\n",
    "# model_5D = calliope.Model('../model/euro_calliope/eurospores/model.yaml', scenario='config_overrides,res_5D,link_cap_dynamic,freeze-hydro-capacities,max_energy_caps')\n",
    "# model_5D.run()\n",
    "\n",
    "# df_total_cost_5D = model_5D.results.cost.to_series().dropna()\n",
    "# total_cost_optimal_5D = df_total_cost_5D.loc[~df_total_cost_5D.index.map(str).str.contains('co2_emissions')].sum()\n",
    "\n",
    "# energy_cap_df_5D = model_5D.results.energy_cap.to_pandas()\n",
    "# filtered_energy_cap_df_5D = energy_cap_df_5D[~energy_cap_df_5D.index.str.contains(\"demand|transmission\")]\n",
    "\n",
    "#create the model with a resolution of 14 days\n",
    "model_FULL = calliope.Model('C:/Users/Jacob/Desktop/PythonProjects/GAMGA-Calliope v3.9/GAMGA_model/model_FULL.yaml')\n",
    "model_FULL.run()\n",
    "\n",
    "df_total_cost_FULL = model_FULL.results.cost.to_series().dropna()\n",
    "total_cost_optimal_FULL = df_total_cost_FULL.loc[~df_total_cost_FULL.index.map(str).str.contains('co2_emissions')].sum()\n",
    "\n",
    "energy_cap_df_FULL = model_FULL.results.energy_cap.to_pandas()\n",
    "filtered_energy_cap_df_FULL = energy_cap_df_FULL[~energy_cap_df_FULL.index.str.contains(\"demand|transmission\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the capacities in a list\n",
    "initial_capacities_FULL = filtered_energy_cap_df_FULL.values \n",
    "\n",
    "# if a value is lower than 13-5, set the value to 0. This is due to everything below 1e-5 being so low it it not interesting to include\n",
    "initial_capacities_FULL[initial_capacities_FULL < 1e-5] = 0\n",
    "\n",
    "# adjust when using more models\n",
    "optimal_value = total_cost_optimal_FULL # adjust when using more models\n",
    "\n",
    "model = model_14D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Order of technologies is stored. This is to know later on which position in the capacity list corresponds to which technology\n",
    "updates = [\n",
    "    {'tech': tech, 'loc': loc}\n",
    "    for loc_tech in filtered_energy_cap_df_FULL.index\n",
    "    for loc, tech in [loc_tech.split(\"::\")]  # Split index by '::' to separate loc and tech\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look in the model backend at what the values are that it has used to initialize the model\n",
    "input_params = model.backend.access_model_inputs()\n",
    "\n",
    "# Access energy_cap_max and energy_cap_min for each technology\n",
    "energy_cap_max = input_params['energy_cap_max']\n",
    "energy_cap_min = input_params['energy_cap_min']\n",
    "\n",
    "# Convert to DataFrame for filtering\n",
    "energy_cap_max_df = energy_cap_max.to_dataframe()\n",
    "energy_cap_min_df = energy_cap_min.to_dataframe()\n",
    "\n",
    "# Filter out rows with 'demand' or 'free' in the index\n",
    "energy_cap_max_filtered = energy_cap_max_df[~energy_cap_max_df.index.get_level_values('loc_techs').str.contains(\"demand|transmission\")]\n",
    "energy_cap_min_filtered = energy_cap_min_df[~energy_cap_min_df.index.get_level_values('loc_techs').str.contains(\"demand|transmission\")]\n",
    "\n",
    "\n",
    "# Create a dictionary of loc_tech to [min, max] bounds meaning that you will have the loc_tech and their corresponding min max capacity\n",
    "low_up_mapping = {\n",
    "    loc_tech: [\n",
    "        energy_cap_min_filtered.loc[loc_tech, 'energy_cap_min'],\n",
    "        energy_cap_max_filtered.loc[loc_tech, 'energy_cap_max']\n",
    "    ]\n",
    "    for loc_tech in energy_cap_max_filtered.index\n",
    "}\n",
    "\n",
    "# Structure the updates (previously done, which are the tech:, loc: pairs) so that it can eventually be used to put in the backend\n",
    "updates_order = [f\"{update['loc']}::{update['tech']}\" for update in updates]\n",
    "\n",
    "# Put it in such a structure that it can be used for the mutation function. This wants it in a list order\n",
    "low_up_bound = [\n",
    "    low_up_mapping[loc_tech] for loc_tech in updates_order\n",
    "]\n",
    "\n",
    "# Check for 'inf' in upper bounds and adjust if needed\n",
    "for i, (low, up) in enumerate(low_up_bound):\n",
    "    if up == float('inf'):\n",
    "        low_up_bound[i][1] = max_cap_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_energy_cap_max_for_individual(model, updates, individual_values):\n",
    "\n",
    "    # Ensure the length of updates matches the individual's values\n",
    "    if len(updates) != len(individual_values):\n",
    "        raise ValueError(\"Length of updates and individual values must match.\")\n",
    "    \n",
    "    # Update the model with the individual's capacity values\n",
    "    for update, new_cap in zip(updates, individual_values):\n",
    "        tech = update['tech']\n",
    "        loc = update['loc']\n",
    "        \n",
    "        # Construct the location::technology key and update the model\n",
    "        loc_tech_key = f\"{loc}::{tech}\"\n",
    "        model.backend.update_param('energy_cap_max', {loc_tech_key: new_cap})\n",
    "        model.backend.update_param('energy_cap_min', {loc_tech_key: new_cap})\n",
    "    \n",
    "    # Run the model for this individual\n",
    "    try:\n",
    "        rerun_model = model.backend.rerun()  # Rerun to capture updated backend parameters\n",
    "\n",
    "        # Calculate the total cost, excluding emission costs\n",
    "        cost_op = rerun_model.results.cost.to_series().dropna()\n",
    "        initial_cost = round(cost_op.loc[~cost_op.index.map(str).str.contains('co2_emissions')].sum(), 2)\n",
    "\n",
    "        total_cost = initial_cost\n",
    "    \n",
    "    except Exception as e:\n",
    "        # If solving fails, set total cost to NaN and print a warning\n",
    "        total_cost = float('inf')\n",
    "        print(\"Warning: Model could not be solved for the individual. Assigning cost as infinite.\")\n",
    "    \n",
    "    return total_cost\n",
    "\n",
    "def slack_feasibility(individual):\n",
    "    cost = update_energy_cap_max_for_individual(model, updates, individual)\n",
    "    individual.cost = cost  # Attach cost attribute to individual\n",
    "    slack_distance = (cost - optimal_value) / optimal_value\n",
    "\n",
    "    # Update feasibility condition based on the new criteria\n",
    "    feasible = slack_distance <= max_slack and cost >= optimal_value\n",
    "    \n",
    "    return feasible \n",
    "\n",
    "def centroidSP(subpop):\n",
    "    centroids = []\n",
    "\n",
    "    # Iterate over each subpopulation and calculate the centroid\n",
    "    for sub in subpop.values():\n",
    "        if not isinstance(sub, list) or not all(isinstance(individual, list) for individual in sub):\n",
    "            raise TypeError(\"Each subpopulation must be a list of lists (individuals).\")\n",
    "        \n",
    "        num_solutions = len(sub)  # Number of solutions in the current subpopulation\n",
    "        num_variables = len(sub[0])  # Number of decision variables\n",
    "        \n",
    "        # Calculate the centroid for each decision variable\n",
    "        centroid = [sum(solution[i] for solution in sub) / num_solutions for i in range(num_variables)]\n",
    "        centroids.append(centroid)  # Append each centroid to the main list in the required format\n",
    "    \n",
    "    return centroids\n",
    "\n",
    "def fitness(subpop, centroids):\n",
    "    distances = []\n",
    "    minimal_distances = []\n",
    "    fitness_SP = {}\n",
    "\n",
    "    # Step 1: Calculate Euclidean Distances for each individual\n",
    "    for q, (subpop_index, subpopulation) in enumerate(subpop.items()):\n",
    "        subpopulation_distances = []\n",
    "        \n",
    "        for individual in subpopulation:\n",
    "            individual_distances = []\n",
    "            \n",
    "            for p, centroid in enumerate(centroids):\n",
    "                if p != q:  # Skip the centroid of the same subpopulation\n",
    "                    # Calculate Euclidean distance\n",
    "                    distance = math.sqrt(sum((individual[i] - centroid[i])**2 for i in range(len(individual))))\n",
    "                    individual_distances.append(distance)\n",
    "            \n",
    "            subpopulation_distances.append(individual_distances)\n",
    "        \n",
    "        distances.append(subpopulation_distances)\n",
    "\n",
    "    # Step 2: Calculate Minimal Distances\n",
    "    for subpopulation_distances in distances:\n",
    "        subpopulation_minimal = [min(individual_distances) for individual_distances in subpopulation_distances]\n",
    "        minimal_distances.append(subpopulation_minimal)\n",
    "\n",
    "    # Step 3: Calculate Fitness SP for each individual\n",
    "    for sp_index, subpopulation in enumerate(minimal_distances, start=1):\n",
    "        fitness_values = [(min_distance,) for min_distance in subpopulation]\n",
    "        fitness_SP[sp_index] = fitness_values\n",
    "\n",
    "    return fitness_SP\n",
    "\n",
    "def fitness_abs(subpop, centroids):\n",
    "    distances = []\n",
    "    minimal_distances = []\n",
    "    fitness_SP = {}\n",
    "\n",
    "    # Step 1: Calculate Distances per Variable for each individual\n",
    "    for q, (subpop_index, subpopulation) in enumerate(subpop.items()):\n",
    "        subpopulation_distances = []\n",
    "        \n",
    "        for individual in subpopulation:\n",
    "            individual_variable_distances = []\n",
    "            \n",
    "            for p, centroid in enumerate(centroids):\n",
    "                if p != q:  # Skip the centroid of the same subpopulation\n",
    "                    variable_distances = [abs(individual[i] - centroid[i]) for i in range(len(individual))]\n",
    "                    individual_variable_distances.append(variable_distances)\n",
    "            \n",
    "            subpopulation_distances.append(individual_variable_distances)\n",
    "        \n",
    "        distances.append(subpopulation_distances)\n",
    "\n",
    "    # Step 2: Calculate Minimal Distances per Variable\n",
    "    for subpopulation_distances in distances:\n",
    "        subpopulation_minimal = []\n",
    "        \n",
    "        for individual_distances in subpopulation_distances:\n",
    "            min_distance_per_variable = [min(distance[i] for distance in individual_distances) for i in range(len(individual_distances[0]))]\n",
    "            subpopulation_minimal.append(min_distance_per_variable)\n",
    "        \n",
    "        minimal_distances.append(subpopulation_minimal)\n",
    "\n",
    "    # Step 3: Calculate Fitness SP for each individual\n",
    "    for sp_index, subpopulation in enumerate(minimal_distances, start=1):\n",
    "        fitness_values = [(min(individual),) for individual in subpopulation]\n",
    "        fitness_SP[sp_index] = fitness_values\n",
    "\n",
    "    return fitness_SP\n",
    "\n",
    "def custom_tournament(subpopulation, k, tournsize=2):\n",
    "    selected = []\n",
    "    zero_fitness_count = 0  # Counter for individuals with fitness (0,)\n",
    "\n",
    "    while len(selected) < k:\n",
    "        # Randomly select `tournsize` individuals for the tournament\n",
    "        tournament = random.sample(subpopulation, tournsize)\n",
    "\n",
    "        # Check if all individuals in the tournament have a fitness of (0,)\n",
    "        if all(ind.fitness.values == (0,) for ind in tournament):\n",
    "            if zero_fitness_count < 2:\n",
    "                # Select the individual with the lowest cost if all fitness values are (0,)\n",
    "                best = min(tournament, key=lambda ind: ind.cost)\n",
    "                selected.append(best)\n",
    "                zero_fitness_count += 1\n",
    "            else:\n",
    "                # Select a random feasible individual if we've reached the max count of (0,) fitness values\n",
    "                feasible_individuals = [ind for ind in subpopulation if ind.fitness.values != (0,)]\n",
    "                if feasible_individuals:\n",
    "                    best = random.choice(feasible_individuals)\n",
    "                    selected.append(best)\n",
    "                else:\n",
    "                    # If no feasible individuals are available, fallback to random selection to avoid empty selection\n",
    "                    best = random.choice(subpopulation)\n",
    "                    selected.append(best)\n",
    "        else:\n",
    "            # Select based on fitness if there are feasible individuals in the tournament\n",
    "            best = max(tournament, key=lambda ind: ind.fitness.values[0])\n",
    "            selected.append(best)\n",
    "\n",
    "    return selected\n",
    "\n",
    "def generate_individual():\n",
    "    adjusted_individual = []\n",
    "    \n",
    "    for cap, (low, up) in zip(initial_capacities_FULL, low_up_bound):\n",
    "        if cap == 0:\n",
    "            # Small chance for installation between % of upper bound\n",
    "            if random.random() < 0.2:  # 10% chance\n",
    "                new_value = random.uniform(0.00001 * up, 0.00001 * up)\n",
    "            else:\n",
    "                # No fallback value, skip adjustment\n",
    "                new_value = 0.0  # Keeps as zero or explicitly sets to 0\n",
    "        else:\n",
    "            # Adjust by a random value between -0.1 and 0.1 of the current value\n",
    "            adjustment = random.uniform(0, 0.001)\n",
    "            new_value = cap * (1 + adjustment)\n",
    "        \n",
    "        # Ensure the new value is within the lower and upper bounds\n",
    "        new_value = max(low, min(up, new_value))\n",
    "        adjusted_individual.append(new_value)\n",
    "    \n",
    "    return adjusted_individual\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMaxDist\", base.Fitness, weights=(1.0,))  # Fitness to maximize distinctiveness\n",
    "creator.create(\"IndividualSP\", list, fitness=creator.FitnessMaxDist, cost=0)  # Individual structure in DEAP\n",
    "\n",
    "# DEAP toolbox setup\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Register the individual and subpopulation initializers\n",
    "toolbox.register(\"individualSP\", tools.initIterate, creator.IndividualSP, generate_individual)\n",
    "toolbox.register(\"subpopulationSP\", tools.initRepeat, list, toolbox.individualSP)\n",
    "\n",
    "#register the operators\n",
    "toolbox.register(\"mate\", tools.cxUniform)\n",
    "toolbox.register(\"elitism\", tools.selBest, fit_attr=\"fitness.values\")\n",
    "toolbox.register(\"tournament\", custom_tournament)\n",
    "toolbox.register(\"mutbound\", tools.mutPolynomialBounded)\n",
    "\n",
    "# Generate subpopulations with multiple individuals\n",
    "subpops_unaltered = [toolbox.subpopulationSP(n=SUBPOP_SIZE) for _ in range(NUM_SUBPOPS)]\n",
    "\n",
    "subpops_SP = {}\n",
    "\n",
    "for p in range(NUM_SUBPOPS):\n",
    "    subpops_SP[p+1] = subpops_unaltered[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feasibility: False, Fitness: (0.0,), Cost: 31966694.99, Subpop: 1, Ind: 1\n",
      "Feasibility: False, Fitness: (0.0,), Cost: 31719025.07, Subpop: 1, Ind: 2\n",
      "Feasibility: False, Fitness: (0.0,), Cost: 31771308.68, Subpop: 1, Ind: 3\n",
      "Feasibility: False, Fitness: (0.0,), Cost: 31917799.09, Subpop: 1, Ind: 4\n",
      "Feasibility: False, Fitness: (0.0,), Cost: 31934859.95, Subpop: 2, Ind: 1\n",
      "Feasibility: False, Fitness: (0.0,), Cost: 31794542.85, Subpop: 2, Ind: 2\n",
      "Feasibility: True, Fitness: (107.31564341447907,), Cost: 31985242.71, Subpop: 2, Ind: 3\n",
      "Feasibility: False, Fitness: (0.0,), Cost: 31937116.08, Subpop: 2, Ind: 4\n"
     ]
    }
   ],
   "source": [
    "#calculate centroids and fitness\n",
    "centroids = centroidSP(subpops_SP)\n",
    "fitness_populations = fitness(subpops_SP, centroids)\n",
    "\n",
    "# Combine the fitness values with each individual\n",
    "for i, subpopulation in subpops_SP.items():\n",
    "    for individual, fit in zip(subpopulation, fitness_populations[i]):\n",
    "        individual.fitness.values = fit \n",
    "\n",
    "for subpop_index, subpopulation in subpops_SP.items():      \n",
    "    # Calculate slack feasibility and set fitness accordingly. This is also where the cost gets assigned as an attribute to the individual\n",
    "    for idx, individual in enumerate(subpopulation):  # Use enumerate to get the index\n",
    "        slack_validity = slack_feasibility(individual)\n",
    "        if slack_validity:\n",
    "            individual.fitness.values = individual.fitness.values\n",
    "        else:\n",
    "            individual.fitness.values = (0,)\n",
    "                \n",
    "        # Print the required details in one line\n",
    "        print(f\"Feasibility: {slack_validity}, Fitness: {individual.fitness.values}, Cost: {individual.cost}, Subpop: {subpop_index}, Ind: {idx + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### initialize all the containers and variables #####################\n",
    "\n",
    "# Initialize containers to store the fitness statistics\n",
    "highest_fitness_per_gen = {i: [] for i in range(1, NUM_SUBPOPS + 1)}  # For highest fitness\n",
    "highest_fitness_sum_per_gen = []  # For sum of highest fitness values across subpopulations\n",
    "\n",
    "best_fitness_sum = float('-inf')  # Start with a very low value\n",
    "best_individuals = []  # List to store the best individuals\n",
    "\n",
    "# Initialize a DataFrame for tracking Best Individuals across generations, including loc_tech columns\n",
    "best_individuals_columns = [\"generation\", \"subpopulation\", \"fitness\", \"cost\", \"values\"] + updates_order\n",
    "best_individuals_df = pd.DataFrame(columns=best_individuals_columns)\n",
    "\n",
    "# State the low and upper bounds for the mutation\n",
    "low = [b[0] for b in low_up_bound]\n",
    "up = [b[1] for b in low_up_bound]\n",
    "\n",
    "# Initialize dictionaries to store the elite selections and ranked list of individuals\n",
    "elite_selections = {}\n",
    "ranked_list_ind = {}\n",
    "\n",
    "# Initialize the generation export buffer\n",
    "generation_export_buffer = []\n",
    "\n",
    "# Initialize a flag to track the first resolution change\n",
    "first_resolution_change = False\n",
    "# Initialize buffers to store individuals that are feasible after resolution change\n",
    "feasible_after_resolution_buffer = []\n",
    "\n",
    "#make sure file does not exists and if so, delete it\n",
    "filename2 = \"feasible_after_resolution.xlsx\"\n",
    "sheet_name = \"Feasible_Individuals\"\n",
    "if os.path.exists(filename2):\n",
    "    os.remove(filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Generation 1 --\n",
      "Replaced with one previous feasible individual - Subpop: 1, Ind: 3, Values: [0.0007733538545109345, 1801.50463105335, 11125.572614216842, 4625.408428259607, 5000.0], Fitness: (0.0,)\n",
      "Replaced with one previous feasible individual - Subpop: 2, Ind: 1, Values: [0.0007824580528582118, 1812.0671912064965, 10985.546164938904, 4672.2637958774285, 5000.0], Fitness: (0.0,)\n",
      "-- Generation 2 --\n",
      "Replaced with one previous feasible individual - Subpop: 1, Ind: 2, Values: [3723.66234978297, 454.19850216121586, 11020.082839931158, 4628.424391465759, 5000.0], Fitness: (4872.935598561629,)\n",
      "-- Generation 3 --\n",
      "Replaced with one previous feasible individual - Subpop: 2, Ind: 4, Values: [0.0003208882291238106, 1784.196395795675, 11977.183463067853, 4625.414052357554, 5000.0], Fitness: (6675.577770215041,)\n",
      "-- Generation 4 --\n",
      "Replaced with one previous feasible individual - Subpop: 1, Ind: 2, Values: [0.0007735442220089138, 10689.486594634882, 14244.137811315482, 4632.233452587545, 4953.3086304522385], Fitness: (6454.802671841964,)\n",
      "-- Generation 5 --\n",
      "Replaced with one previous feasible individual - Subpop: 1, Ind: 1, Values: [0.0007735442220089138, 10689.486594634882, 14244.137811315482, 4632.233452587545, 4953.3086304522385], Fitness: (7131.677135948702,)\n",
      "Replaced with one previous feasible individual - Subpop: 2, Ind: 4, Values: [0.0003208882291238106, 1784.196395795675, 14805.141580170277, 4625.414052357554, 5000.0], Fitness: (10344.524649891237,)\n",
      "-- Generation 6 --\n",
      "Replaced with one previous feasible individual - Subpop: 1, Ind: 1, Values: [2729.3714950182703, 11648.08139989689, 11020.082839931158, 713.6033209874768, 4953.3086304522385], Fitness: (11228.882029263461,)\n",
      "Replaced with one previous feasible individual - Subpop: 1, Ind: 3, Values: [4119.967591896839, 11648.08139989689, 11020.082839931158, 4632.233452587545, 4955.061873876572], Fitness: (10675.355672575673,)\n",
      "Replaced with one previous feasible individual - Subpop: 2, Ind: 4, Values: [5017.6478958295065, 1641.8419030254308, 14805.141580170277, 6084.137225447266, 5000.0], Fitness: (10997.670281957033,)\n",
      "-- Generation 7 --\n",
      "Replaced with one previous feasible individual - Subpop: 2, Ind: 2, Values: [0.0003208882291238106, 1430.9591460411416, 14805.141580170277, 6084.137225447266, 5000.0], Fitness: (12156.072472048154,)\n",
      "Replaced with one previous feasible individual - Subpop: 2, Ind: 4, Values: [0.0003208882291238106, 922.2030684398472, 14805.141580170277, 4625.414052357554, 5000.0], Fitness: (12184.904533472896,)\n",
      "-- Generation 8 --\n",
      "Replaced with one previous feasible individual - Subpop: 1, Ind: 2, Values: [2729.3714950182703, 14177.017006280883, 11020.082839931158, 713.6033209874768, 4953.3086304522385], Fitness: (14354.555283600293,)\n",
      "Replaced with one previous feasible individual - Subpop: 2, Ind: 1, Values: [0.0003208882291238106, 1430.9591460411416, 14805.141580170277, 6084.137225447266, 5000.0], Fitness: (11187.990605779034,)\n",
      "Replaced with one previous feasible individual - Subpop: 2, Ind: 3, Values: [5017.6478958295065, 1430.9591460411416, 14536.538293039719, 5791.816149536103, 5000.0], Fitness: (10686.366990311308,)\n",
      "-- Generation 9 --\n",
      "Replaced with one previous feasible individual - Subpop: 1, Ind: 1, Values: [2729.3714950182703, 10767.554954055842, 11020.082839931158, 713.6033209874768, 4953.5544086583395], Fitness: (11406.992600693718,)\n",
      "Replaced with one previous feasible individual - Subpop: 1, Ind: 3, Values: [2729.3714950182703, 14177.017006280883, 11020.082839931158, 713.6033209874768, 4953.3086304522385], Fitness: (14332.113339548288,)\n",
      "Replaced with one previous feasible individual - Subpop: 2, Ind: 1, Values: [0.0003208882291238106, 1430.9591460411416, 14805.141580170277, 6084.137225447266, 5000.0], Fitness: (13457.864195063656,)\n",
      "-- Generation 10 --\n",
      "Replaced with one previous feasible individual - Subpop: 1, Ind: 3, Values: [151.53662534126443, 14177.017006280883, 9703.994297275738, 713.6033209874768, 4953.3086304522385], Fitness: (14792.686553954152,)\n",
      "Replaced with one previous feasible individual - Subpop: 2, Ind: 3, Values: [0.0003208882291238106, 1430.9591460411416, 14805.141580170277, 6084.137225447266, 5000.0], Fitness: (13184.301302122387,)\n",
      "-- Generation 11 --\n",
      "Replaced with one previous feasible individual - Subpop: 1, Ind: 4, Values: [151.53662534126443, 14177.017006280883, 9703.994297275738, 713.6033209874768, 4953.3086304522385], Fitness: (14793.260587446348,)\n",
      "Replaced with one previous feasible individual - Subpop: 2, Ind: 4, Values: [0.0001288859561542503, 1430.9591460411416, 14811.799169446085, 6084.137225447266, 5000.0], Fitness: (12123.29232313738,)\n",
      "-- Generation 12 --\n",
      "Replaced with one previous feasible individual - Subpop: 1, Ind: 1, Values: [151.53662534126443, 14177.017006280883, 9703.994297275738, 713.6033209874768, 4953.3086304522385], Fitness: (15101.861235009052,)\n",
      "-- Generation 13 --\n",
      "-- Generation 14 --\n",
      "Replaced with one previous feasible individual - Subpop: 2, Ind: 2, Values: [8206.08876940072, 1430.9591460411416, 14805.141580170277, 6084.137225447266, 5000.0], Fitness: (16720.499529091263,)\n",
      "-- Generation 15 --\n",
      "Replaced with one previous feasible individual - Subpop: 1, Ind: 2, Values: [151.53662534126443, 14751.951889842689, 10006.534827754818, 762.1279493871222, 4734.249187317625], Fitness: (17160.304007043378,)\n",
      "-- Generation 16 --\n",
      "Replaced with one previous feasible individual - Subpop: 2, Ind: 2, Values: [8461.129668390082, 957.3412433239245, 11521.677789394871, 6084.137225447266, 4477.144868414607], Fitness: (16464.634904391598,)\n",
      "Replaced with one previous feasible individual - Subpop: 2, Ind: 4, Values: [8206.08876940072, 1430.9591460411416, 14986.31306206738, 293.47199721418747, 4477.144868414607], Fitness: (15701.034618024634,)\n",
      "-- Generation 17 --\n",
      "Replaced with one previous feasible individual - Subpop: 1, Ind: 2, Values: [151.53662534126443, 14751.951889842689, 10006.534827754818, 762.1279493871222, 4734.249187317625], Fitness: (16479.453796742917,)\n",
      "Replaced with one previous feasible individual - Subpop: 2, Ind: 1, Values: [8461.129668390082, 957.3412433239245, 11521.677789394871, 6084.137225447266, 4477.144868414607], Fitness: (17056.78898114396,)\n",
      "-- Generation 18 --\n",
      "-- Generation 19 --\n",
      "Replaced with one previous feasible individual - Subpop: 1, Ind: 2, Values: [74.81139092061184, 14833.959711998697, 7240.368784244589, 117.12087269364986, 4734.249187317625], Fitness: (17596.65020865248,)\n",
      "-- Generation 20 --\n",
      "Replaced with one previous feasible individual - Subpop: 1, Ind: 2, Values: [5154.39946143398, 14825.533697213652, 7240.368784244589, 483.34297028434474, 4734.249187317625], Fitness: (16369.118659040701,)\n",
      "Replaced with one previous feasible individual - Subpop: 1, Ind: 3, Values: [74.81139092061184, 14833.959711998697, 7240.368784244589, 117.12087269364986, 4793.937899576036], Fitness: (18182.14906453662,)\n",
      "Replaced with one previous feasible individual - Subpop: 2, Ind: 1, Values: [8206.08876940072, 957.3412433239245, 12175.183768076067, 8064.7558432891, 4713.3531209416315], Fitness: (18010.900435183357,)\n",
      "-- Generation 21 --\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 118\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subpop_index, subpopulation \u001b[38;5;129;01min\u001b[39;00m offspring\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    115\u001b[0m     \n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# Step 1: Calculate slack feasibility\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, individual \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(subpopulation):\n\u001b[1;32m--> 118\u001b[0m         slack_validity \u001b[38;5;241m=\u001b[39m \u001b[43mslack_feasibility\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindividual\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m slack_validity:\n\u001b[0;32m    121\u001b[0m             feasible_individuals[subpop_index]\u001b[38;5;241m.\u001b[39mappend(individual)\n",
      "Cell \u001b[1;32mIn[7], line 35\u001b[0m, in \u001b[0;36mslack_feasibility\u001b[1;34m(individual)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslack_feasibility\u001b[39m(individual):\n\u001b[1;32m---> 35\u001b[0m     cost \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_energy_cap_max_for_individual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindividual\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     individual\u001b[38;5;241m.\u001b[39mcost \u001b[38;5;241m=\u001b[39m cost  \u001b[38;5;66;03m# Attach cost attribute to individual\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     slack_distance \u001b[38;5;241m=\u001b[39m (cost \u001b[38;5;241m-\u001b[39m optimal_value) \u001b[38;5;241m/\u001b[39m optimal_value\n",
      "Cell \u001b[1;32mIn[7], line 19\u001b[0m, in \u001b[0;36mupdate_energy_cap_max_for_individual\u001b[1;34m(model, updates, individual_values)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Run the model for this individual\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     rerun_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrerun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Rerun to capture updated backend parameters\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Calculate the total cost, excluding emission costs\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     cost_op \u001b[38;5;241m=\u001b[39m rerun_model\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mcost\u001b[38;5;241m.\u001b[39mto_series()\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[1;32mc:\\Users\\Jacob\\miniconda3\\envs\\calliope\\lib\\site-packages\\calliope\\backend\\pyomo\\interface.py:346\u001b[0m, in \u001b[0;36mBackendInterfaceMethods.rerun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrerun\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 346\u001b[0m     _opt, new_model \u001b[38;5;241m=\u001b[39m rerun_pyomo_model(\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_opt, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    348\u001b[0m     )\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_opt \u001b[38;5;241m=\u001b[39m _opt\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_model\n",
      "File \u001b[1;32mc:\\Users\\Jacob\\miniconda3\\envs\\calliope\\lib\\site-packages\\calliope\\backend\\pyomo\\interface.py:162\u001b[0m, in \u001b[0;36mrerun_pyomo_model\u001b[1;34m(model_data, backend_model, opt)\u001b[0m\n\u001b[0;32m    160\u001b[0m timings \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    161\u001b[0m log_time(logger, timings, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_creation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 162\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43maccess_pyomo_model_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m run_mode \u001b[38;5;241m=\u001b[39m backend_model\u001b[38;5;241m.\u001b[39m__calliope_run_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplan\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Jacob\\miniconda3\\envs\\calliope\\lib\\site-packages\\calliope\\backend\\pyomo\\interface.py:28\u001b[0m, in \u001b[0;36maccess_pyomo_model_inputs\u001b[1;34m(backend_model)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maccess_pyomo_model_inputs\u001b[39m(backend_model):\n\u001b[0;32m     22\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m    If the user wishes to inspect the parameter values used as inputs in the backend\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m    model, they can access a new Dataset of all the backend model inputs, including\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    defaults applied where the user did not specify anything for a loc::tech\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m     all_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     29\u001b[0m         i\u001b[38;5;241m.\u001b[39mname: get_var(backend_model, i\u001b[38;5;241m.\u001b[39mname, sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m backend_model\u001b[38;5;241m.\u001b[39mcomponent_objects()\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(i, po\u001b[38;5;241m.\u001b[39mbase\u001b[38;5;241m.\u001b[39mparam\u001b[38;5;241m.\u001b[39mIndexedParam)\n\u001b[0;32m     32\u001b[0m     }\n\u001b[0;32m     33\u001b[0m     all_param_ds \u001b[38;5;241m=\u001b[39m reorganise_xarray_dimensions(xr\u001b[38;5;241m.\u001b[39mDataset(all_params))\n\u001b[0;32m     34\u001b[0m     all_param_ds \u001b[38;5;241m=\u001b[39m string_to_datetime(backend_model, all_param_ds)\n",
      "File \u001b[1;32mc:\\Users\\Jacob\\miniconda3\\envs\\calliope\\lib\\site-packages\\calliope\\backend\\pyomo\\interface.py:29\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maccess_pyomo_model_inputs\u001b[39m(backend_model):\n\u001b[0;32m     22\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m    If the user wishes to inspect the parameter values used as inputs in the backend\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m    model, they can access a new Dataset of all the backend model inputs, including\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    defaults applied where the user did not specify anything for a loc::tech\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     all_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m---> 29\u001b[0m         i\u001b[38;5;241m.\u001b[39mname: \u001b[43mget_var\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m backend_model\u001b[38;5;241m.\u001b[39mcomponent_objects()\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(i, po\u001b[38;5;241m.\u001b[39mbase\u001b[38;5;241m.\u001b[39mparam\u001b[38;5;241m.\u001b[39mIndexedParam)\n\u001b[0;32m     32\u001b[0m     }\n\u001b[0;32m     33\u001b[0m     all_param_ds \u001b[38;5;241m=\u001b[39m reorganise_xarray_dimensions(xr\u001b[38;5;241m.\u001b[39mDataset(all_params))\n\u001b[0;32m     34\u001b[0m     all_param_ds \u001b[38;5;241m=\u001b[39m string_to_datetime(backend_model, all_param_ds)\n",
      "File \u001b[1;32mc:\\Users\\Jacob\\miniconda3\\envs\\calliope\\lib\\site-packages\\calliope\\backend\\pyomo\\util.py:191\u001b[0m, in \u001b[0;36mget_var\u001b[1;34m(backend_model, var, dims, sparse, expr)\u001b[0m\n\u001b[0;32m    187\u001b[0m da \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray\u001b[38;5;241m.\u001b[39mfrom_series(result_with_dim_names)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m# Order of dimension set items is sorted by pd.Series above and may no longer match\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# the input calliope data set order. So we reorder the array dimensions here.\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m da_resorted \u001b[38;5;241m=\u001b[39m da\u001b[38;5;241m.\u001b[39mreindex(\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{dim: \u001b[38;5;28mgetattr\u001b[39m(backend_model, dim)\u001b[38;5;241m.\u001b[39m_ordered_values \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m dims}\n\u001b[0;32m    193\u001b[0m )\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m da_resorted\n",
      "File \u001b[1;32mc:\\Users\\Jacob\\miniconda3\\envs\\calliope\\lib\\site-packages\\xarray\\core\\dataarray.py:1617\u001b[0m, in \u001b[0;36mDataArray.reindex\u001b[1;34m(self, indexers, method, tolerance, copy, fill_value, **indexers_kwargs)\u001b[0m\n\u001b[0;32m   1614\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sentinel:\n\u001b[0;32m   1615\u001b[0m         fill_value[_THIS_ARRAY] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m-> 1617\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_temp_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1623\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1624\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_temp_dataset(ds)\n",
      "File \u001b[1;32mc:\\Users\\Jacob\\miniconda3\\envs\\calliope\\lib\\site-packages\\xarray\\core\\dataset.py:2948\u001b[0m, in \u001b[0;36mDataset.reindex\u001b[1;34m(self, indexers, method, tolerance, copy, fill_value, **indexers_kwargs)\u001b[0m\n\u001b[0;32m   2744\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreindex\u001b[39m(\n\u001b[0;32m   2745\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2746\u001b[0m     indexers: Mapping[Any, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2751\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mindexers_kwargs: Any,\n\u001b[0;32m   2752\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dataset:\n\u001b[0;32m   2753\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Conform this object onto a new set of indexes, filling in\u001b[39;00m\n\u001b[0;32m   2754\u001b[0m \u001b[38;5;124;03m    missing values with ``fill_value``. The default fill value is NaN.\u001b[39;00m\n\u001b[0;32m   2755\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2946\u001b[0m \n\u001b[0;32m   2947\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex(\n\u001b[0;32m   2949\u001b[0m         indexers,\n\u001b[0;32m   2950\u001b[0m         method,\n\u001b[0;32m   2951\u001b[0m         tolerance,\n\u001b[0;32m   2952\u001b[0m         copy,\n\u001b[0;32m   2953\u001b[0m         fill_value,\n\u001b[0;32m   2954\u001b[0m         sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   2955\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mindexers_kwargs,\n\u001b[0;32m   2956\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Jacob\\miniconda3\\envs\\calliope\\lib\\site-packages\\xarray\\core\\dataset.py:2977\u001b[0m, in \u001b[0;36mDataset._reindex\u001b[1;34m(self, indexers, method, tolerance, copy, fill_value, sparse, **indexers_kwargs)\u001b[0m\n\u001b[0;32m   2974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bad_dims:\n\u001b[0;32m   2975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid reindex dimensions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbad_dims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2977\u001b[0m variables, indexes \u001b[38;5;241m=\u001b[39m \u001b[43malignment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_variables\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2978\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2979\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2980\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxindexes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2984\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2985\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2986\u001b[0m \u001b[43m    \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2987\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2988\u001b[0m coord_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coord_names)\n\u001b[0;32m   2989\u001b[0m coord_names\u001b[38;5;241m.\u001b[39mupdate(indexers)\n",
      "File \u001b[1;32mc:\\Users\\Jacob\\miniconda3\\envs\\calliope\\lib\\site-packages\\xarray\\core\\alignment.py:600\u001b[0m, in \u001b[0;36mreindex_variables\u001b[1;34m(variables, sizes, indexes, indexers, method, tolerance, copy, fill_value, sparse)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (int_indexer \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m    599\u001b[0m     masked_dims\u001b[38;5;241m.\u001b[39madd(dim)\n\u001b[1;32m--> 600\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mint_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    601\u001b[0m     unchanged_dims\u001b[38;5;241m.\u001b[39madd(dim)\n\u001b[0;32m    603\u001b[0m int_indexers[dim] \u001b[38;5;241m=\u001b[39m int_indexer\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36marray_equal\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Jacob\\miniconda3\\envs\\calliope\\lib\\site-packages\\numpy\\core\\numeric.py:2463\u001b[0m, in \u001b[0;36marray_equal\u001b[1;34m(a1, a2, equal_nan)\u001b[0m\n\u001b[0;32m   2461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   2462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m equal_nan:\n\u001b[1;32m-> 2463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(asarray(\u001b[43ma1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma2\u001b[49m)\u001b[38;5;241m.\u001b[39mall())\n\u001b[0;32m   2464\u001b[0m \u001b[38;5;66;03m# Handling NaN values if equal_nan is True\u001b[39;00m\n\u001b[0;32m   2465\u001b[0m a1nan, a2nan \u001b[38;5;241m=\u001b[39m isnan(a1), isnan(a2)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "g = 0\n",
    "while g < GENERATIONS: \n",
    "    g += 1\n",
    "    print(f\"-- Generation {g} --\")\n",
    "\n",
    "    offspring = {}\n",
    "    current_individuals = []  # Track individuals contributing to this generation's highest sum\n",
    "    highest_fitness_sum = 0  # Initialize the sum of highest fitness for this generation\n",
    "    export_data = []\n",
    "\n",
    "    for subpop_index, subpopulation in subpops_SP.items():\n",
    "        # Compute and store fitness values, excluding (0,) fitness values\n",
    "        fitness_values = [ind.fitness.values[0] for ind in subpopulation if ind.fitness.values[0] != 0]\n",
    "\n",
    "        # Calculate the highest fitness\n",
    "        if fitness_values:\n",
    "            highest_fitness = max(fitness_values)\n",
    "        else:\n",
    "            highest_fitness = 0\n",
    "        highest_fitness_per_gen[subpop_index].append(highest_fitness)\n",
    "\n",
    "        # Add to the total highest fitness sum for this generation\n",
    "        highest_fitness_sum += highest_fitness\n",
    "\n",
    "        # Identify the individual(s) contributing to the highest fitness\n",
    "        best_individual = min(\n",
    "            (ind for ind in subpopulation if ind.fitness.values[0] == highest_fitness),\n",
    "            key=lambda ind: getattr(ind, 'cost', float('inf'))  # Select based on cost\n",
    "        )\n",
    "\n",
    "        # Add this individual to current_individuals\n",
    "        current_individuals.append({\n",
    "            \"subpop_index\": subpop_index,\n",
    "            \"fitness\": best_individual.fitness.values[0],\n",
    "            \"cost\": getattr(best_individual, 'cost', 0),\n",
    "            \"generation\": g,  # Add the generation\n",
    "            \"values\": list(best_individual)\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################## operator code ##############################################\n",
    "\n",
    "        #Rank the individuals for if they are needed when some mutated individuals are deemed infeasible\n",
    "        ranked_list_ind[subpop_index] = toolbox.elitism(subpopulation, len(subpopulation))\n",
    "        # Select the next generation individuals\n",
    "        # Preserve the top ~% as elites and select the rest through tournament selection\n",
    "        elite_count = int(0.2 * len(subpopulation))\n",
    "        elite_selections[subpop_index] = toolbox.elitism(subpopulation, elite_count)\n",
    "        offspring[subpop_index] = (elite_selections[subpop_index] + toolbox.tournament(subpopulation, (len(subpopulation) - elite_count)))\n",
    "        # Clone the selected individuals\n",
    "        offspring[subpop_index] = list(map(toolbox.clone, offspring[subpop_index]))\n",
    "\n",
    "\n",
    "\n",
    "        # Apply crossover\n",
    "        for child1, child2 in zip(offspring[subpop_index][::2], offspring[subpop_index][1::2]): \n",
    "            if random.random() < 0.5:  # Use updated crossover probability\n",
    "                toolbox.mate(child1, child2, indpb=INDCROSS) \n",
    "                del child1.fitness.values \n",
    "                del child2.fitness.values\n",
    "                del child1.cost\n",
    "                del child2.cost \n",
    "\n",
    "\n",
    "\n",
    "        # Apply mutation\n",
    "        for mutant in offspring[subpop_index]:\n",
    "            if random.random() <= 1:\n",
    "                # Apply mutPolynomialBounded with shared bounds\n",
    "                mutant, = toolbox.mutbound(mutant, low=low, up=up, eta=ETAV, indpb=INDMUT)\n",
    "                mutant[:] = [max(0, val) for val in mutant]  # Ensure values are non-negative\n",
    "                # Delete fitness to ensure re-evaluation\n",
    "                if hasattr(mutant.fitness, 'values'):\n",
    "                    del mutant.fitness.values\n",
    "                if hasattr(mutant.cost, 'values'):\n",
    "                    del mutant.cost\n",
    "\n",
    "############################################## storing best individual ##############################################\n",
    "\n",
    "    # Append the total highest fitness sum for this generation\n",
    "    highest_fitness_sum_per_gen.append(highest_fitness_sum)\n",
    "\n",
    "\n",
    "    # Track Best Individuals and Update DataFrame\n",
    "    if highest_fitness_sum > best_fitness_sum:\n",
    "        best_fitness_sum = highest_fitness_sum\n",
    "        best_individuals = current_individuals.copy()  # Update the best individuals\n",
    "\n",
    "        # Add new best individuals directly to the DataFrame so they can eventually be exported to the excel file\n",
    "        for ind in best_individuals:\n",
    "            row = {\n",
    "                \"generation\": ind['generation'],\n",
    "                \"subpopulation\": ind['subpop_index'],\n",
    "                \"fitness\": ind['fitness'],\n",
    "                \"cost\": ind['cost'],\n",
    "                \"values\": ', '.join(map(str, ind['values']))\n",
    "            }\n",
    "            \n",
    "            # Add loc_tech values from the individual\n",
    "            for loc_tech, value in zip(updates_order, ind['values']):\n",
    "                row[loc_tech] = value\n",
    "            \n",
    "            # Append the row to the DataFrame\n",
    "            best_individuals_df = pd.concat([best_individuals_df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "############################################## calculating centroids and feasibility ##############################################\n",
    "\n",
    "    # Calculate slack feasibility and set fitness accordingly\n",
    "    feasible_individuals = {subpop_index: [] for subpop_index in offspring.keys()}  \n",
    "    infeasible_individuals = {subpop_index: [] for subpop_index in offspring.keys()}\n",
    "\n",
    "    for subpop_index, subpopulation in offspring.items():\n",
    "        \n",
    "        # Step 1: Calculate slack feasibility\n",
    "        for idx, individual in enumerate(subpopulation):\n",
    "            slack_validity = slack_feasibility(individual)\n",
    "\n",
    "            if slack_validity:\n",
    "                feasible_individuals[subpop_index].append(individual)\n",
    "                # save the individuals that are feasible after the first resolution change has been initialized\n",
    "                if first_resolution_change:  \n",
    "                        # Store the feasible individual in the buffer\n",
    "                        row = {\n",
    "                            \"generation\": g,\n",
    "                            \"subpopulation\": subpop_index,\n",
    "                            \"individual\": f\"Subpop {subpop_index}, Ind {idx + 1}\",\n",
    "                            \"cost\": getattr(individual, 'cost', 'N/A')\n",
    "                        }\n",
    "                        \n",
    "                        # Add loc_tech values\n",
    "                        for loc_tech, value in zip(updates_order, individual):\n",
    "                            row[loc_tech] = value\n",
    "                        \n",
    "                        feasible_after_resolution_buffer.append(row)\n",
    "                    \n",
    "            else:\n",
    "                # Replace infeasible individuals with elites\n",
    "                if elite_selections[subpop_index]:  # Ensure there are elites left for this subpopulation\n",
    "                    replacement = elite_selections[subpop_index].pop(0)  # Take one elite from this subpopulation's selection\n",
    "                    subpopulation[idx] = toolbox.clone(replacement)  # Replace with a clone of the elite\n",
    "                    feasible_individuals[subpop_index].append(subpopulation[idx])  # Add to feasible\n",
    "                    print(f\"Replaced with Elite - Subpop: {subpop_index}, Ind: {idx + 1}, Values: {subpopulation[idx]}, Fitness: {subpopulation[idx].fitness.values}\")\n",
    "\n",
    "                # # Replace with a random feasible individual from ranked_list_ind    \n",
    "                elif ranked_list_ind[subpop_index]:\n",
    "                    replacement = random.choice(ranked_list_ind[subpop_index])\n",
    "                    ranked_list_ind[subpop_index].remove(replacement)  # Remove the selected individual\n",
    "                    subpopulation[idx] = toolbox.clone(replacement)\n",
    "                    feasible_individuals[subpop_index].append(subpopulation[idx]) # add to infeasible\n",
    "                    print(f\"Replaced with one previous feasible individual - Subpop: {subpop_index}, Ind: {idx + 1}, Values: {subpopulation[idx]}, Fitness: {subpopulation[idx].fitness.values}\")\n",
    "\n",
    "                # Assign zero fitness if no replacements are available\n",
    "                else:\n",
    "                    # If no elites or previous fit values are left, assign zero fitness and continue\n",
    "                    individual.fitness.values = (0,)\n",
    "                    infeasible_individuals[subpop_index].append(individual)\n",
    "                    print(f\"Infeasible - Subpop: {subpop_index}, Ind: {idx + 1}, Values: {individual}, Fitness: {individual.fitness.values}\")\n",
    "\n",
    " \n",
    "    # Step 2: Calculate centroids and fitness for feasible individuals\n",
    "    if feasible_individuals:  \n",
    "        centroids_offspring = copy.deepcopy(centroidSP(feasible_individuals))\n",
    "        fitness_SP_offspring = fitness(feasible_individuals, centroids_offspring)\n",
    "\n",
    "        # Assign calculated fitness to feasible individuals\n",
    "        for subpop_index, individuals in feasible_individuals.items():\n",
    "            if individuals:  # Ensure there are individuals to process\n",
    "                for idx, individual in enumerate(individuals):\n",
    "                    individual.fitness.values = fitness_SP_offspring[subpop_index][idx]\n",
    "            else:\n",
    "                print(f\"Warning: No feasible individuals in Subpopulation {subpop_index}\")\n",
    "\n",
    "    # Combine feasible and infeasible individuals to form the new offspring\n",
    "    for subpop_index in offspring.keys():\n",
    "        # Combine and update offspring\n",
    "        offspring[subpop_index] = feasible_individuals[subpop_index] + infeasible_individuals[subpop_index]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################## value and resolution changes ##############################################\n",
    "\n",
    "    # change parameters and or resolution after n generations\n",
    "    if g == value_change_1:\n",
    "        print(\"Changing parameters (eta = 1000).\")\n",
    "        ETAV = 1000\n",
    "\n",
    "    if g == value_change_2:\n",
    "        print(\"Changing parameters (eta = 10000).\")\n",
    "        ETAV = 10000\n",
    "\n",
    "    if g == resolution_change_1:\n",
    "        print(\"Changing resolution.\")\n",
    "        first_resolution_change = True\n",
    "        model = model_full\n",
    "    \n",
    "\n",
    "    # if g == resolution_change_2:\n",
    "    #     print(\"Changing resolution to 6H.\")\n",
    "    #     model = model_FULL\n",
    "\n",
    "    # Update the subpopulations with the new offspring\n",
    "    subpops_SP = offspring\n",
    "\n",
    "\n",
    "\n",
    "############################################## code to export to excel ##############################################\n",
    "\n",
    "    # Export data for specific generations to excel\n",
    "    generation_export_buffer.clear()\n",
    "\n",
    "    for subpop_index, subpopulation in subpops_SP.items():\n",
    "        for idx, individual in enumerate(subpopulation):\n",
    "            if individual.fitness.values[0] == 0:\n",
    "                continue  # Skip individuals with zero fitness\n",
    "            \n",
    "            row = {\n",
    "                \"generation\": g,\n",
    "                \"subpopulation\": subpop_index,\n",
    "                \"individual\": f\"Subpop {subpop_index}, Ind {idx + 1}\",\n",
    "                \"fitness\": individual.fitness.values[0],\n",
    "                \"cost\": getattr(individual, 'cost', 'N/A')\n",
    "            }\n",
    "            \n",
    "            for loc_tech, value in zip(updates_order, individual):\n",
    "                row[loc_tech] = value  # Map loc::tech values\n",
    "            \n",
    "            generation_export_buffer.append(row)\n",
    "\n",
    "    # Export data for specific generations\n",
    "    if g == 1 or g % 10 == 0 or g == GENERATIONS:\n",
    "        if generation_export_buffer:\n",
    "            # Convert buffer to DataFrame\n",
    "            df_gen = pd.DataFrame(generation_export_buffer)\n",
    "            \n",
    "            # Sort the data for clarity\n",
    "            df_gen = df_gen.sort_values(\n",
    "                by=[\"subpopulation\", \"fitness\"], \n",
    "                ascending=[True, False]\n",
    "            ).reset_index(drop=True)\n",
    "            \n",
    "            # Write to an Excel file with a separate sheet for each generation\n",
    "            filename = \"individual_generation_interval.xlsx\"\n",
    "            sheet_name = f\"Generation_{g}\"\n",
    "            \n",
    "            # Remove the file if it exists\n",
    "            if g == 1 and os.path.exists(filename):\n",
    "                os.remove(filename) \n",
    "\n",
    "            # Open Excel file in append mode or create if it doesn't exist\n",
    "            try:\n",
    "                with pd.ExcelWriter(filename, mode='a', engine='openpyxl') as writer:\n",
    "                    df_gen.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            except FileNotFoundError:\n",
    "                with pd.ExcelWriter(filename, mode='w', engine='openpyxl') as writer:\n",
    "                    df_gen.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "\n",
    "\n",
    "############################ code to export feasible individuals after resolution change ##############################################\n",
    "      \n",
    "    # Check if the buffer has feasible individuals\n",
    "    if feasible_after_resolution_buffer:\n",
    "        # Convert buffer to DataFrame\n",
    "        df_feasible = pd.DataFrame(feasible_after_resolution_buffer)\n",
    "\n",
    "        # Define the new file name and sheet name\n",
    "        filename2 = \"feasible_after_resolution.xlsx\"\n",
    "        sheet_name = \"Feasible_Individuals\"\n",
    "\n",
    "        # Check if the file exists\n",
    "        if not os.path.exists(filename2):\n",
    "            # If the file doesn't exist, create a new one\n",
    "            with pd.ExcelWriter(filename2, mode='w', engine='openpyxl') as writer:\n",
    "                df_feasible.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            print(f\"File '{filename2}' created with data.\")\n",
    "        else:\n",
    "            # Append data to the existing file\n",
    "            with pd.ExcelWriter(filename2, mode='a', engine='openpyxl', if_sheet_exists='overlay') as writer:\n",
    "                df_feasible.to_excel(writer, sheet_name=sheet_name, index=False, startrow=writer.sheets[sheet_name].max_row)\n",
    "            print(f\"Data appended to '{filename2}'.\")\n",
    "\n",
    "        # Clear the buffer after exporting\n",
    "        feasible_after_resolution_buffer.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Best Individuals to Excel after the loop finishes\n",
    "filename = \"individual_generation_interval.xlsx\"\n",
    "try:\n",
    "    with pd.ExcelWriter(filename, mode='a', engine='openpyxl') as writer:\n",
    "        best_individuals_df.to_excel(writer, sheet_name=\"Best_Individuals\", index=False)\n",
    "except FileNotFoundError:\n",
    "    with pd.ExcelWriter(filename, mode='w', engine='openpyxl') as writer:\n",
    "        best_individuals_df.to_excel(writer, sheet_name=\"Best_Individuals\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nBest Individuals Across All Generations:\")\n",
    "print(f\"Highest Fitness Sum: {best_fitness_sum}\")\n",
    "for ind in best_individuals:\n",
    "    print(f\"  Generation {ind['generation']} - Subpopulation {ind['subpop_index']} - \"\n",
    "        f\"Fitness: {ind['fitness']:.2f}, Cost: {ind['cost']:.2f}, Values: {ind['values']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
